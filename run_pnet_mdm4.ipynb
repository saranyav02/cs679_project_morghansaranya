{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f519f377",
   "metadata": {},
   "source": [
    "# MDM4 Pathway Model Training\n",
    "\n",
    "This notebook trains and evaluates the **MDM4PathwayNet** model on the P1000 prostate cancer CNV dataset.\n",
    "\n",
    "It assumes that:\n",
    "- `data_loader.py`, `pathways.py`, and `model_mdm4.py` are in the same directory as this notebook.\n",
    "- The data files  \n",
    "  `P1000_data_CNA_paper.csv`, `response_paper.csv`,  \n",
    "  `training_set_0.csv`, `validation_set.csv`, `test_set.csv`  \n",
    "  are available in the locations expected by `ProstateMDM4Dataset`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "751b5ee9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from data_loader import ProstateMDM4Dataset\n",
    "from pathways import get_mdm4_masks_for_gene_order\n",
    "from model_mdm4 import MDM4PathwayNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c06843a",
   "metadata": {},
   "source": [
    "1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1722605",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "base_dir = Path.cwd()\n",
    "\n",
    "dataset = ProstateMDM4Dataset()\n",
    "\n",
    "(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    X_test,\n",
    "    y_test,\n",
    "    genes,  # list of gene names in the same order as the columns of X_*\n",
    ") = dataset.get_train_val_test()\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Val shape:  \", X_val.shape, y_val.shape)\n",
    "print(\"Test shape: \", X_test.shape, y_test.shape)\n",
    "\n",
    "\n",
    "def summarize_labels(name, y):\n",
    "    vals, counts = np.unique(y, return_counts=True)\n",
    "    total = counts.sum()\n",
    "    props = {int(v): counts[i] / float(total) for i, v in enumerate(vals)}\n",
    "    print(f\"{name} label distribution:\", props)\n",
    "\n",
    "\n",
    "summarize_labels(\"Train\", y_train)\n",
    "summarize_labels(\"Val\",   y_val)\n",
    "summarize_labels(\"Test\",  y_test)\n",
    "\n",
    "print(\"Number of genes (CNV_amp features):\", len(genes))\n",
    "print(\"Example genes:\", genes[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ce2d4",
   "metadata": {},
   "source": [
    "2) Build KEGG + Reactome MDM4 masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57ce78e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "kegg_mask_df, reactome_mask_df = get_mdm4_masks_for_gene_order(genes)\n",
    "\n",
    "print(\"KEGG MDM4 mask shape:     \", kegg_mask_df.shape)\n",
    "print(\"Reactome MDM4 mask shape: \", reactome_mask_df.shape)\n",
    "\n",
    "kegg_mask = kegg_mask_df.to_numpy(dtype=\"float32\")          # (n_genes, n_kegg)\n",
    "reactome_mask = reactome_mask_df.to_numpy(dtype=\"float32\")  # (n_genes, n_reactome)\n",
    "\n",
    "assert list(kegg_mask_df.index) == genes\n",
    "assert list(reactome_mask_df.index) == genes\n",
    "\n",
    "print(\"Done building data + MDM4 pathway masks.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248b48b2",
   "metadata": {},
   "source": [
    "3) Torch setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f075e7b2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Convert numpy arrays to torch tensors\n",
    "X_train_t = torch.from_numpy(X_train.astype(\"float32\"))\n",
    "X_val_t   = torch.from_numpy(X_val.astype(\"float32\"))\n",
    "X_test_t  = torch.from_numpy(X_test.astype(\"float32\"))\n",
    "\n",
    "# BCEWithLogitsLoss expects float targets 0.0 / 1.0\n",
    "y_train_t = torch.from_numpy(y_train.astype(\"float32\"))\n",
    "y_val_t   = torch.from_numpy(y_val.astype(\"float32\"))\n",
    "y_test_t  = torch.from_numpy(y_test.astype(\"float32\"))\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_t)\n",
    "val_ds   = TensorDataset(X_val_t,   y_val_t)\n",
    "test_ds  = TensorDataset(X_test_t,  y_test_t)\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc1b0fa",
   "metadata": {},
   "source": [
    "4) Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9c6d02",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model = MDM4PathwayNet(\n",
    "    n_genes=len(genes),\n",
    "    kegg_mask=kegg_mask,\n",
    "    reactome_mask=reactome_mask,\n",
    "    hidden_dim=32,\n",
    "    dropout=0.2,\n",
    ").to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=5e-5,\n",
    "    weight_decay=1e-5,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89eada2f",
   "metadata": {},
   "source": [
    "5) Training + evaluation helpers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b9d7e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_epoch(loader, train: bool):\n",
    "    if train:\n",
    "        model.train()\n",
    "    else:\n",
    "        model.eval()\n",
    "\n",
    "    total_loss = 0.0\n",
    "    all_targets = []\n",
    "    all_logits = []\n",
    "\n",
    "    for xb, yb in loader:\n",
    "        xb = xb.to(device)\n",
    "        yb = yb.to(device)\n",
    "\n",
    "        if train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        logits = model(xb)  # (batch,)\n",
    "        loss = criterion(logits, yb)\n",
    "\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "        all_targets.append(yb.detach().cpu().numpy())\n",
    "        all_logits.append(logits.detach().cpu().numpy())\n",
    "\n",
    "    total_loss /= len(loader.dataset)\n",
    "    all_targets = np.concatenate(all_targets)\n",
    "    all_logits = np.concatenate(all_logits)\n",
    "\n",
    "    # Convert logits → probabilities\n",
    "    probs = 1.0 / (1.0 + np.exp(-all_logits))\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    acc = accuracy_score(all_targets, preds)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_targets, probs)\n",
    "    except ValueError:\n",
    "        auc = np.nan  # e.g. if only one class present in a split\n",
    "\n",
    "    return total_loss, acc, auc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5ca16b",
   "metadata": {},
   "source": [
    "6) Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b14e7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 200\n",
    "best_val_auc = -np.inf\n",
    "best_state = None\n",
    "\n",
    "patience = 15\n",
    "epochs_no_improve = 0\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train_loss, train_acc, train_auc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_acc, val_auc = run_epoch(val_loader, train=False)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch:03d} | \"\n",
    "        f\"Train loss {train_loss:.4f}, acc {train_acc:.3f}, AUC {train_auc:.3f} | \"\n",
    "        f\"Val loss {val_loss:.4f}, acc {val_acc:.3f}, AUC {val_auc:.3f}\"\n",
    "    )\n",
    "\n",
    "    if val_auc > best_val_auc + 1e-4:  # tiny margin to avoid noise\n",
    "        best_val_auc = val_auc\n",
    "        best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        epochs_no_improve = 0\n",
    "        print(f\"  → New best val AUC: {best_val_auc:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"  → No improvement in val AUC for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\n",
    "                f\"\\nEarly stopping triggered at epoch {epoch}. \"\n",
    "                f\"Best val AUC = {best_val_auc:.4f}\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "elapsed_sec = end_time - start_time\n",
    "elapsed_min = elapsed_sec / 60.0\n",
    "print(f\"\\nTotal training time: {elapsed_sec:.1f} s (~{elapsed_min:.2f} min)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be18c7f0",
   "metadata": {},
   "source": [
    "7) Performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba79cc85",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if best_state is not None:\n",
    "    model.load_state_dict(best_state)\n",
    "\n",
    "test_loss, test_acc, test_auc = run_epoch(test_loader, train=False)\n",
    "print(\"\\nTest performance (best val AUC model):\")\n",
    "print(f\"  Loss: {test_loss:.4f}\")\n",
    "print(f\"  Acc : {test_acc:.3f}\")\n",
    "print(f\"  AUC : {test_auc:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
